Deep Learning Models for Fine-grained Image Classification of Closely Related Objects: 
An Application in Enhancing Brain Tumour Classification from Obscured MRI
This repository contains the implementation of a Convolutional Neural Network (CNN) 
designed to enhance the classification of brain tumours from MRI images, specifically 
addressing challenges posed by obscured or blurry MRI. The project employs TensorFlow 
and PyTorch libraries to demonstrate the application of deep learning in medical image 
analysis, with a focus on fine-grained image classification of closely related objects. 
Additionally, the model is deployed using Flask to provide a simple web interface for 
easy interaction and real-time classification.
Project Overview
The aim of this project is to develop and optimize a CNN model that can accurately classify 
different types of brain tumours (glioma, meningioma, pituitary tumours) and normal brain 
tissue, even under conditions where MRI images are obscured or blurred. The project explores 
various data preprocessing techniques, model architectures, and evaluation metrics to improve 
diagnostic accuracy and aid in neuro-oncology. The Flask deployment allows users to upload 
MRI images and receive predictions directly through a web interface.
Install required Python libraries:
Requirements
Python 3.8+
TensorFlow 2.x
PyTorch
OpenCV
NumPy
Matplotlib
Scikit-Learn
Seaborn
Flask
Data
The dataset used in this project includes MRI images categorized into four classes: glioma, 
meningioma, pituitary tumours, and normal brain scans sourced from Kaggle database 
(https://www.kaggle.com/datasets/mohammadhossein77/brain-tumors-dataset). Each class has been 
pre-processed to simulate obscured conditions and augmented to enhance the model's ability to generalize.
Model Architecture
The CNN architecture includes multiple convolutional layers, max-pooling layers, dropout layers, and fully 
connected layers, designed specifically for the classification of medical images with high accuracy.
Evaluation
Model performance is evaluated using the classification report and confusion matrix generated by evaluating 
the model. These metrics help in understanding the effectiveness of the model across different classes and 
in obscured image conditions.
